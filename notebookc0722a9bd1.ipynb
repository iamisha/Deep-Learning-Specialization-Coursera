{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ishahitang/notebookc0722a9bd1?scriptVersionId=224911187\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"#Install Dependencies\n\n_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_","metadata":{"id":"7mGmQbAO5pQb"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"JGJspIl90XhV","outputId":"2c77bec5-0288-4b50-8bfe-6dbf92be651c","trusted":true,"execution":{"iopub.status.busy":"2025-02-27T15:43:16.123036Z","iopub.execute_input":"2025-02-27T15:43:16.123324Z","iopub.status.idle":"2025-02-27T15:43:16.28682Z","shell.execute_reply.started":"2025-02-27T15:43:16.123302Z","shell.execute_reply":"2025-02-27T15:43:16.285823Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Download YOLOv7 repository and install requirements\n\n# !git clone https://github.com/WongKinYiu/yolov7\n# %cd yolov7\n# !pip install -r requirements.txt\n\n# current version of YOLOv7 is not compatible with pytorch>1.12.1 and numpy>1.20.1\n# until the appropriate changes get made to the main repository, we will be using a fork containing the patched code\n# you can track the progress here: https://github.com/roboflow/notebooks/issues/27\n!git clone https://github.com/RahulMht/yolov7.git\n%cd yolov7\n!pip install -r requirements.txt","metadata":{"id":"nD-uPyQ_2jiN","outputId":"d3714868-1fe2-4c33-fce2-e5c65780bc9c","trusted":true,"execution":{"iopub.status.busy":"2025-02-27T15:43:16.288019Z","iopub.execute_input":"2025-02-27T15:43:16.288246Z","iopub.status.idle":"2025-02-27T15:43:24.579191Z","shell.execute_reply.started":"2025-02-27T15:43:16.288222Z","shell.execute_reply":"2025-02-27T15:43:24.578288Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Download Correctly Formatted Custom Data\n\nNext, we'll download our dataset in the right format. Use the `YOLOv7 PyTorch` export. Note that this model requires YOLO TXT annotations, a custom YAML file, and organized directories. The roboflow export writes this for us and saves it in the correct spot.\n","metadata":{"id":"mtJ24mPlyF-S"}},{"cell_type":"code","source":"!pip install roboflow\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"LvZfAEJ6jnzNOrP52hab\")\nproject = rf.workspace(\"upone\").project(\"vehicules_detection_v1-blacd\")\nversion = project.version(2)\ndataset = version.download(\"yolov7\")\n","metadata":{"id":"ovKgrVN8ygdW","outputId":"6ee2a63e-b744-4250-92f2-1ceb7780a1be","trusted":true,"execution":{"iopub.status.busy":"2025-02-27T15:43:24.581169Z","iopub.execute_input":"2025-02-27T15:43:24.581449Z","iopub.status.idle":"2025-02-27T15:45:14.872593Z","shell.execute_reply.started":"2025-02-27T15:43:24.581423Z","shell.execute_reply":"2025-02-27T15:45:14.87166Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Begin Custom Training\n\nWe're ready to start custom training.\n\nNOTE: We will only modify one of the YOLOv7 training defaults in our example: `epochs`. We will adjust from 300 to 100 epochs in our example for speed. If you'd like to change other settings, see details in [our accompanying blog post](https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial/).","metadata":{"id":"bHfT9gEiBsBd"}},{"cell_type":"code","source":"# download COCO starting checkpoint\n%cd /kaggle/working/yolov7\n!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt","metadata":{"id":"bUbmy674bhpD","outputId":"1f272a48-19d6-4537-c36f-102cfbf1779d","trusted":true,"execution":{"iopub.status.busy":"2025-02-27T15:45:14.873849Z","iopub.execute_input":"2025-02-27T15:45:14.87415Z","iopub.status.idle":"2025-02-27T15:45:17.780754Z","shell.execute_reply.started":"2025-02-27T15:45:14.874114Z","shell.execute_reply":"2025-02-27T15:45:17.779723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# run this cell to begin training\n%cd /kaggle/working/yolov7\n!WANDB_MODE=offline python train.py --batch 25 --epochs 20 --data {dataset.location}/data.yaml --weights 'yolov7_training.pt' --device 0\n","metadata":{"id":"1iqOPKjr22mL","outputId":"24b5f809-062a-4084-982e-0b9ec42f6f83","trusted":true,"execution":{"iopub.status.busy":"2025-02-27T15:45:17.781743Z","iopub.execute_input":"2025-02-27T15:45:17.782037Z","iopub.status.idle":"2025-02-28T02:58:32.400287Z","shell.execute_reply.started":"2025-02-27T15:45:17.782012Z","shell.execute_reply":"2025-02-28T02:58:32.39922Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation\n\nWe can evaluate the performance of our custom training using the provided evalution script.\n\nNote we can adjust the below custom arguments. For details, see [the arguments accepted by detect.py](https://github.com/WongKinYiu/yolov7/blob/main/detect.py#L154).","metadata":{"id":"0W0MpUaTCJro"}},{"cell_type":"code","source":"# Run evaluation\n!python detect.py --weights runs/train/exp/weights/best.pt --conf 0.1 --source {dataset.location}/test/images\n","metadata":{"id":"N4cfnLtTCIce","outputId":"330b64ff-b4fc-421e-a612-c2e0d096dbe1","trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:58:32.401339Z","iopub.execute_input":"2025-02-28T02:58:32.401637Z","iopub.status.idle":"2025-02-28T02:59:14.943315Z","shell.execute_reply.started":"2025-02-28T02:58:32.401609Z","shell.execute_reply":"2025-02-28T02:59:14.942506Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#display inference on ALL test images\n\nimport glob\nfrom IPython.display import Image, display\n\ni = 0\nlimit = 10000 # max images to print\nfor imageName in glob.glob('/kaggle/working/yolov7/runs/detect/exp/*.jpg'): #assuming JPG\n    if i < limit:\n      display(Image(filename=imageName))\n      print(\"\\n\")\n    i = i + 1\n","metadata":{"id":"6AGhNOSSHY4_","trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:59:14.944285Z","iopub.execute_input":"2025-02-28T02:59:14.944696Z","execution_failed":"2025-02-28T03:42:33.041Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nshutil.make_archive('train_folder', 'zip', '/kaggle/working/yolov7/runs')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T03:36:31.679909Z","iopub.execute_input":"2025-02-28T03:36:31.680187Z","iopub.status.idle":"2025-02-28T03:38:38.45195Z","shell.execute_reply.started":"2025-02-28T03:36:31.680167Z","shell.execute_reply":"2025-02-28T03:38:38.451191Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Reparameterize for Inference\n\nhttps://github.com/WongKinYiu/yolov7/blob/main/tools/reparameterization.ipynb","metadata":{"id":"aMumI7a2JDAN"}},{"cell_type":"markdown","source":"## Deploy Model on Roboflow\n\nOnce you have finished training your YOLOv7 model, youâ€™ll have a set of trained weights ready for use. These weights will be in the `/content/runs/train/exp/weights/best.pt` folder of your project. You can upload your model weights to Roboflow Deploy to use your trained weights on our infinitely scalable infrastructure.\n\nThe `.deploy()` function in the [Roboflow pip package](https://docs.roboflow.com/python) supports uploading YOLOv7 weights.\n\n**Before you run this code, make sure you create a new Version in the Roboflow dashboard following the instructions we covered earlier. Fill in your project name, workspace, and version number below.**\n\n[Learn how to retrieve your project ID](https://docs.roboflow.com/api-reference/workspace-and-project-ids)\n[Learn how to retrieve your API key.](https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key)","metadata":{"id":"ibfSUYFt-hS9"}},{"cell_type":"code","source":"project = rf.workspace(\"workspace\").project(\"project\")\ndataset = project.version(1)\n\nproject.version(dataset.version).deploy(model_type=\"yolov7\", model_path=f\"/content/runs/train/exp/weights/\")","metadata":{"id":"2CGv-etN-hS9","outputId":"19668f63-bfc9-41fd-a9f1-54017aa1b175","trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:04:26.44938Z","iopub.execute_input":"2025-02-28T04:04:26.449628Z","iopub.status.idle":"2025-02-28T04:04:26.460076Z","shell.execute_reply.started":"2025-02-28T04:04:26.449594Z","shell.execute_reply":"2025-02-28T04:04:26.458703Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Deploy Your Model to the Edge\n\nIn addition to using the Roboflow hosted API for deployment, you can use [Roboflow Inference](https://inference.roboflow.com), an open source inference solution that has powered millions of API calls in production environments. Inference works with CPU and GPU, giving you immediate access to a range of devices, from the NVIDIA Jetson to TRT-compatible devices to ARM CPU devices.\n\nWith Roboflow Inference, you can self-host and deploy your model on-device. You can deploy applications using the [Inference Docker containers](https://inference.roboflow.com/quickstart/docker/) or the pip package.\n\nFor example, to install Inference on a device with an NVIDIA GPU, we can use:\n\n```\ndocker pull roboflow/roboflow-inference-server-gpu\n```\n\nThen we can run inference via HTTP:\n\n```python\nimport requests\n\nworkspace_id = \"\"\nmodel_id = \"\"\nimage_url = \"\"\nconfidence = 0.75\napi_key = \"\"\niou_threshold = 0.5\n\ninfer_payload = {\n    \"image\": {\n        \"type\": \"url\",\n        \"value\": image_url,\n    },\n    \"confidence\": confidence,\n    \"iou_threshold\": iou_threshold,\n    \"api_key\": api_key,\n}\nres = requests.post(\n    f\"http://localhost:9001/{workspace_id}/{model_id}\",\n    json=infer_object_detection_payload,\n)\n\npredictions = res.json()\n```\n\nAbove, set your Roboflow workspace ID, model ID, and API key.\n\n- [Find your workspace and model ID](https://docs.roboflow.com/api-reference/workspace-and-project-ids?ref=blog.roboflow.com)\n- [Find your API key](https://docs.roboflow.com/api-reference/authentication?ref=blog.roboflow.com#retrieve-an-api-key)\n\nAlso, set the URL of an image on which you want to run inference. This can be a local file.\n\n_To use your YOLOv5 model commercially with Inference, you will need a Roboflow Enterprise license, through which you gain a pass-through license for using YOLOv5. An enterprise license also grants you access to features like advanced device management, multi-model containers, auto-batch inference, and more._","metadata":{"id":"VX-fN9YO-hS-"}},{"cell_type":"markdown","source":"# Next steps\n\nCongratulations, you've trained a custom YOLOv7 model! Next, start thinking about deploying and [building an MLOps pipeline](https://docs.roboflow.com) so your model gets better the more data it sees in the wild.","metadata":{"id":"LVpCFeU-K4gb"}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}